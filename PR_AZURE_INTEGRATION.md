# Pull Request: Azure AI Foundry Integration

## üìã Summary

Add optional Azure AI Foundry integration to LLMSelect, enabling routing of all LLM provider APIs (OpenAI, Anthropic, Gemini, Mistral) through Azure for centralized billing, enterprise governance, and unified monitoring.

## üéØ Motivation

**User Need:**
- Centralized billing for all LLM providers under a single Azure subscription
- Enterprise governance and compliance through Azure
- Simplified API key management with one Azure credential
- Better monitoring and cost tracking via Azure Monitor

**Current Limitation:**
- LLMSelect connects directly to each provider's API
- Multiple billing relationships (OpenAI, Anthropic, Google, Mistral)
- Harder to track consolidated costs
- Limited enterprise governance options

**Solution:**
Route all API calls through Azure AI Foundry, which provides:
- Single Azure invoice for all providers
- OpenAI-compatible API format for unified interface
- Azure Monitor integration for logging and metrics
- Private endpoints and compliance features

## ‚ú® Features Added

### 1. Azure Configuration Layer
- Environment-based Azure configuration in `llmselect/config.py`
- Support for Azure endpoint, API key, and API version
- Model-to-deployment name mappings for 14 models
- Configurable via environment variables

### 2. Dual-Mode Routing
- **Azure Mode**: Routes through Azure AI Foundry (when `USE_AZURE_FOUNDRY=true`)
- **Direct Mode**: Uses direct provider APIs (default, when `USE_AZURE_FOUNDRY=false`)
- Seamless switching via environment variable
- Zero code changes required to switch modes

### 3. LLM Service Enhancement
- New Azure-specific methods: `_call_azure_foundry()`, `_stream_azure_foundry()`
- Deployment name resolution with clear error messages
- OpenAI-compatible format for all providers through Azure
- Full streaming support (SSE) through Azure

### 4. Comprehensive Documentation
- **AZURE_QUICK_REFERENCE.md**: 3-step setup guide
- **AZURE_FOUNDRY_SETUP.md**: Detailed Azure resource setup with CLI commands
- **AZURE_INTEGRATION_GUIDE.md**: Configuration, testing, and troubleshooting
- **AZURE_IMPLEMENTATION_SUMMARY.md**: Technical implementation details
- Updated README.md with Azure integration section

## üìÅ Files Changed

### Modified Files (5)
1. **llmselect/config.py** (~50 lines added)
   - Added Azure configuration variables
   - Added model deployment name mappings
   - Supports environment-based customization

2. **llmselect/services/llm.py** (~130 lines added)
   - Enhanced `__init__()` to accept Azure parameters
   - Updated `invoke()` and `invoke_stream()` for Azure routing
   - Added `_get_azure_deployment_name()` helper
   - Added `_call_azure_foundry()` for non-streaming
   - Added `_stream_azure_foundry()` for streaming

3. **llmselect/container.py** (~15 lines modified)
   - Updated `create_service_container()` to pass Azure config
   - Extracts Azure settings from Flask app config

4. **.env.example** (~35 lines added)
   - Added Azure configuration section
   - 14 deployment name mapping examples
   - Inline documentation

5. **README.md** (~30 lines added)
   - New "Azure AI Foundry Integration" section
   - Environment variables table
   - Links to all Azure documentation

### New Files (4 documentation files)
1. **AZURE_QUICK_REFERENCE.md** (~200 lines)
   - 3-step setup guide
   - Environment variables cheat sheet
   - Testing and troubleshooting commands
   - Common issues and quick fixes

2. **AZURE_FOUNDRY_SETUP.md** (~350 lines)
   - Azure resource creation with Azure CLI
   - Model deployment instructions
   - API endpoint documentation
   - Model mapping reference table
   - Cost comparison analysis
   - Troubleshooting guide
   - Migration strategy

3. **AZURE_INTEGRATION_GUIDE.md** (~400 lines)
   - Step-by-step configuration
   - Deployment name mapping guide
   - Testing checklist (manual + automated)
   - Monitoring and debugging
   - Security best practices
   - Cost tracking commands

4. **AZURE_IMPLEMENTATION_SUMMARY.md** (~450 lines)
   - Technical implementation details
   - Architecture diagrams
   - Design decisions explained
   - Testing strategy
   - Known limitations
   - Next steps roadmap

## üèóÔ∏è Architecture

### Request Flow (Azure Enabled)
```
User Request
  ‚Üì
Backend Routes
  ‚Üì
LLMService.invoke() / invoke_stream()
  ‚Üì
Check: use_azure == true? ‚Üí YES
  ‚Üì
_get_azure_deployment_name(model)
  ‚Üì
_call_azure_foundry() / _stream_azure_foundry()
  ‚Üì
Azure AI Foundry (OpenAI-compatible API)
  ‚Üì
Provider APIs (OpenAI, Anthropic, Gemini, Mistral)
  ‚Üì
Response ‚Üí Azure ‚Üí LLMService ‚Üí Frontend
```

### Request Flow (Azure Disabled - Default)
```
User Request
  ‚Üì
Backend Routes
  ‚Üì
LLMService.invoke() / invoke_stream()
  ‚Üì
Check: use_azure == false? ‚Üí YES
  ‚Üì
Direct provider methods (_call_openai, _call_anthropic, etc.)
  ‚Üì
Provider APIs (direct)
  ‚Üì
Response ‚Üí LLMService ‚Üí Frontend
```

## üîß Configuration Example

### Enable Azure Routing
```bash
# In .env file
USE_AZURE_FOUNDRY=true
AZURE_AI_FOUNDRY_ENDPOINT=https://your-resource.openai.azure.com
AZURE_AI_FOUNDRY_KEY=your-azure-api-key
AZURE_AI_FOUNDRY_API_VERSION=2024-02-15-preview

# Map models to Azure deployment names
AZURE_DEPLOYMENT_GPT4O=gpt-4o-deployment
AZURE_DEPLOYMENT_CLAUDE_35_SONNET=claude-35-sonnet-deployment
AZURE_DEPLOYMENT_GEMINI_15_PRO=gemini-15-pro-deployment
AZURE_DEPLOYMENT_MISTRAL_LARGE=mistral-large-deployment
```

### Disable Azure Routing (Default)
```bash
# In .env file (or omit entirely)
USE_AZURE_FOUNDRY=false
```

## üß™ Testing

### Automated Tests
- ‚úÖ No syntax errors in modified Python files
- ‚úÖ Type hints validated
- ‚úÖ Imports correct
- ‚ö†Ô∏è Unit tests with Azure mocks (pending - requires test environment)

### Manual Testing Required
Since actual Azure resources aren't provisioned yet:

**Prerequisites for testing:**
1. Create Azure AI Foundry resource
2. Deploy 2-3 test models
3. Configure environment variables

**Test cases:**
- [ ] App starts with Azure enabled
- [ ] Single-model chat (non-streaming) works
- [ ] Single-model chat (streaming) works
- [ ] Comparison mode with 2+ models works
- [ ] Error handling for missing deployment
- [ ] Switch to direct mode and verify fallback
- [ ] Verify billing appears in Azure portal
- [ ] Check Azure Monitor for API calls

### Validation Commands
```bash
# Verify config
cat .env | grep AZURE_

# Test Azure endpoint
curl -X POST "${AZURE_AI_FOUNDRY_ENDPOINT}/openai/deployments/test-deployment/chat/completions?api-version=2024-02-15-preview" \
  -H "api-key: ${AZURE_AI_FOUNDRY_KEY}" \
  -d '{"messages":[{"role":"user","content":"test"}]}'

# Check deployment mappings
cat llmselect/config.py | grep AZURE_DEPLOYMENT_MAPPINGS -A 20
```

## üîí Security Considerations

### What's Secure
‚úÖ Azure API key stored in environment (not committed)  
‚úÖ Dual-mode prevents vendor lock-in  
‚úÖ No changes to existing authentication flow  
‚úÖ Error messages don't leak credentials  
‚úÖ Azure credentials separate from provider credentials  

### What to Monitor
- Azure API key rotation policy
- Network access to Azure endpoints
- Cost monitoring and budget alerts
- Unusual API usage patterns

### Production Recommendations
- Use Azure Managed Identity instead of API keys
- Configure Azure Private Endpoints
- Set up Azure Monitor alerts
- Enable Azure WAF for protection
- Rotate credentials regularly

## üìä Performance Impact

### Expected
- **Latency**: +10-30ms per request (Azure routing overhead)
- **Throughput**: No change (Azure handles high load)
- **Streaming**: No noticeable difference (SSE works through Azure)

### Benefits
- Centralized rate limiting through Azure
- Better DDoS protection
- Geographic routing options
- Automatic failover capabilities

## üîÑ Backward Compatibility

### ‚úÖ Fully Backward Compatible
- **Default Behavior**: Azure integration is **disabled by default**
- **Existing Users**: No changes required, app works as before
- **Direct APIs**: Still fully supported
- **API Keys**: User's provider API keys still work in direct mode
- **No Breaking Changes**: All existing features work identically

### Migration Path
1. **Phase 1** (Current): Azure optional, disabled by default
2. **Phase 2** (Future): Recommend Azure in docs, still optional
3. **Phase 3** (Optional Future): Azure default, direct APIs opt-in

Users can stay on direct APIs indefinitely if desired.

## üí∞ Cost Impact

### Azure Costs
- **API Pricing**: Azure has **0% markup** on provider pricing
- **Same Cost**: Calls through Azure cost the same as direct APIs
- **Infrastructure**: Azure AI Foundry resource has minimal monthly cost (~$0-10)
- **Benefits**: Consolidated billing, better cost tracking

### Cost Tracking
```bash
# View costs by resource
az consumption usage list \
  --start-date $(date -u -d '7 days ago' '+%Y-%m-%d') \
  --end-date $(date -u '+%Y-%m-%d')
```

## üìö Documentation Quality

### Comprehensive Coverage
- **4 new documentation files** (~1200 lines total)
- **Quick reference** for immediate value
- **Setup guide** with Azure CLI commands
- **Integration guide** with testing checklists
- **Implementation details** for developers

### Audience Targeting
- **Operators**: Quick reference and integration guide
- **Developers**: Implementation summary
- **Azure Admins**: Setup guide with CLI commands
- **End Users**: README section explaining benefits

## üöÄ Deployment Plan

### Prerequisites
1. Provision Azure AI Foundry resource
2. Deploy models in Azure portal
3. Get endpoint and API key

### Deployment Steps
1. **Merge PR** to main branch
2. **Configure environment** variables on target environment
3. **Set Azure flag** (`USE_AZURE_FOUNDRY=true`)
4. **Restart application** to load new config
5. **Test single model** chat to verify routing
6. **Test comparison mode** with multiple models
7. **Monitor Azure logs** to confirm API calls
8. **Verify billing** in Azure Cost Management

### Rollback Plan
1. Set `USE_AZURE_FOUNDRY=false` in environment
2. Restart application
3. App reverts to direct provider APIs
4. No data loss, no disruption

## üêõ Known Limitations

### Current
1. **No UI Toggle**: Azure mode is environment-variable only (no Settings UI toggle)
2. **Static Mappings**: Deployment names hardcoded in config.py (not database-driven)
3. **No Managed Identity**: Uses API key authentication (not Azure AD)
4. **Single Endpoint**: No multi-region failover yet

### Planned Enhancements
- Add Azure toggle in Settings UI
- Support per-user deployment mappings
- Add Managed Identity support
- Multi-region failover
- Cost tracking in UI

## ‚úÖ Checklist

### Code Quality
- [x] No syntax errors
- [x] Type hints added
- [x] Error handling implemented
- [x] Logging maintained
- [x] Code formatted (Black)
- [x] No hardcoded secrets

### Documentation
- [x] README updated
- [x] .env.example updated
- [x] Quick reference created
- [x] Setup guide created
- [x] Integration guide created
- [x] Implementation summary created
- [x] Inline code comments added

### Testing
- [x] Syntax validation passed
- [ ] Unit tests with mocks (pending test environment)
- [ ] Integration tests with Azure (pending Azure setup)
- [ ] Manual testing checklist documented

### Security
- [x] No credentials in code
- [x] Environment-based secrets
- [x] Error messages safe
- [x] Backward compatible
- [x] No breaking changes

### Deployment
- [x] Rollback plan documented
- [x] Configuration guide complete
- [x] Azure setup documented
- [x] Migration path defined
- [ ] Azure resources provisioned (user action required)

## üéì Learning Resources

### For Reviewers
- Start with: `AZURE_QUICK_REFERENCE.md`
- Then read: `AZURE_IMPLEMENTATION_SUMMARY.md`
- Deep dive: `llmselect/services/llm.py` (methods `_call_azure_foundry`, `_stream_azure_foundry`)

### For Users
- Quick setup: `AZURE_QUICK_REFERENCE.md`
- Full setup: `AZURE_FOUNDRY_SETUP.md`
- Testing: `AZURE_INTEGRATION_GUIDE.md`

### For Operators
- Configuration: `.env.example` + `AZURE_INTEGRATION_GUIDE.md`
- Monitoring: `AZURE_INTEGRATION_GUIDE.md` (Monitoring section)
- Troubleshooting: `AZURE_QUICK_REFERENCE.md` (Troubleshooting section)

## üìù Summary

**What this PR does:**
Adds optional Azure AI Foundry integration for centralized billing and enterprise governance while maintaining full backward compatibility with direct provider APIs.

**Key benefits:**
- üí∞ Single Azure invoice for all providers
- üîê Enterprise compliance and governance
- üìä Better monitoring and cost tracking
- üîÑ Completely optional and reversible

**Risk level:** **Low**
- Default behavior unchanged (Azure disabled)
- Existing functionality untouched
- Easy rollback (environment variable)
- Comprehensive documentation
- No breaking changes

**Next steps after merge:**
1. Provision Azure resources (optional for users who want this feature)
2. Configure environment variables
3. Test with actual Azure endpoints
4. Consider adding UI toggle in future enhancement

**Status:** ‚úÖ Ready for Review | üß™ Pending Azure Testing | üìö Fully Documented
