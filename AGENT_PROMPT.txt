Implement Phase 2: Comparison Mode UI for LLMSelect

Read SUPERPROMPT_COPILOT_CODE.md for complete specifications and implementation plan.

OBJECTIVE:
Build the comparison mode feature - the core value proposition of LLMSelect. Enable users to select 2-4 LLM models and compare their responses side-by-side from a single prompt.

KEY DELIVERABLES:
1. Backend: ComparisonResult model, persistence service, comparison history API endpoints
2. Frontend: ModelSelector component, ResponseCard component, ComparisonMode UI with side-by-side layout
3. Features: Multi-model selection, response metadata display, voting/preferences, comparison history
4. Testing: 90%+ backend coverage, 80%+ frontend coverage
5. Documentation: Update CHANGELOG.md, DECISIONS.md, README.md

CRITICAL REQUIREMENTS:
- Security P0: JWT auth on all endpoints, CSRF protection, input validation, no secrets exposed
- Follow existing patterns: Service layer, dependency injection, Marshmallow schemas
- Code quality: Black formatting, type hints, PropTypes, comprehensive tests
- No breaking changes to existing /api/v1/compare endpoint (extend, don't modify)

START BY:
1. Reading SUPERPROMPT_COPILOT_CODE.md completely
2. Reviewing PRIORITIES_SUMMARY.md for context
3. Examining llmselect/routes/chat.py (existing compare endpoint)
4. Reading src/App.js (current frontend structure)

ESTIMATED TIME: 2-3 weeks (21 days)

SUCCESS CRITERIA:
- Users can compare 2-4 models side-by-side
- Comparisons persist to database with voting capability
- All tests passing, CI/CD green, no security issues
- Documentation updated

See SUPERPROMPT_COPILOT_CODE.md for detailed implementation plan, code examples, and decision-making framework.
